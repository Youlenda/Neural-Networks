{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2-q4-1layer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD0E2bzWRNOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('house_data.csv')\n",
        "dataset = df.values\n",
        "\n",
        "# df\n",
        "# dataset.shape, dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJgyHoFOSeVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dataset[:, 0:13]\n",
        "y = dataset[:, 13]\n",
        "\n",
        "# x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKUQrX6mW9oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scale = min_max_scaler.fit_transform(x)\n",
        "\n",
        "TransformY = preprocessing.MinMaxScaler()\n",
        "y_scale = TransformY.fit_transform(y.reshape(y.shape[0],1))\n",
        "\n",
        "#x_scale, y_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJFXbyK8Xdg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scale, y_scale, test_size=0.2)\n",
        "\n",
        "#x_train.shape,x_test.shape,x_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wbou-8WZ8V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(13,)),\n",
        "    Dense(1, kernel_initializer='normal')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NArrkODraJDW",
        "colab_type": "code",
        "outputId": "4277fa64-7168-47da-ce7a-53e9a792ef54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_37 (Dense)             (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 151\n",
            "Trainable params: 151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05KwQSJxa80q",
        "colab_type": "code",
        "outputId": "89a48d5f-1dd2-4fe6-d87d-b35cdc584ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trained_model = model.fit(x_train, y_train, batch_size=16, epochs=100, validation_split=0.2) #validation_data=(x_val, y_val))\n",
        "\n",
        "history = trained_model.history"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 323 samples, validate on 81 samples\n",
            "Epoch 1/100\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.1368 - val_loss: 0.0972\n",
            "Epoch 2/100\n",
            "323/323 [==============================] - 0s 221us/step - loss: 0.0842 - val_loss: 0.0696\n",
            "Epoch 3/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0628 - val_loss: 0.0621\n",
            "Epoch 4/100\n",
            "323/323 [==============================] - 0s 241us/step - loss: 0.0551 - val_loss: 0.0586\n",
            "Epoch 5/100\n",
            "323/323 [==============================] - 0s 185us/step - loss: 0.0508 - val_loss: 0.0542\n",
            "Epoch 6/100\n",
            "323/323 [==============================] - 0s 220us/step - loss: 0.0468 - val_loss: 0.0497\n",
            "Epoch 7/100\n",
            "323/323 [==============================] - 0s 186us/step - loss: 0.0430 - val_loss: 0.0458\n",
            "Epoch 8/100\n",
            "323/323 [==============================] - 0s 201us/step - loss: 0.0394 - val_loss: 0.0422\n",
            "Epoch 9/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0361 - val_loss: 0.0388\n",
            "Epoch 10/100\n",
            "323/323 [==============================] - 0s 211us/step - loss: 0.0334 - val_loss: 0.0355\n",
            "Epoch 11/100\n",
            "323/323 [==============================] - 0s 211us/step - loss: 0.0302 - val_loss: 0.0328\n",
            "Epoch 12/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0279 - val_loss: 0.0301\n",
            "Epoch 13/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0256 - val_loss: 0.0279\n",
            "Epoch 14/100\n",
            "323/323 [==============================] - 0s 221us/step - loss: 0.0240 - val_loss: 0.0259\n",
            "Epoch 15/100\n",
            "323/323 [==============================] - 0s 205us/step - loss: 0.0223 - val_loss: 0.0245\n",
            "Epoch 16/100\n",
            "323/323 [==============================] - 0s 207us/step - loss: 0.0211 - val_loss: 0.0231\n",
            "Epoch 17/100\n",
            "323/323 [==============================] - 0s 204us/step - loss: 0.0199 - val_loss: 0.0220\n",
            "Epoch 18/100\n",
            "323/323 [==============================] - 0s 180us/step - loss: 0.0190 - val_loss: 0.0210\n",
            "Epoch 19/100\n",
            "323/323 [==============================] - 0s 184us/step - loss: 0.0182 - val_loss: 0.0201\n",
            "Epoch 20/100\n",
            "323/323 [==============================] - 0s 226us/step - loss: 0.0175 - val_loss: 0.0195\n",
            "Epoch 21/100\n",
            "323/323 [==============================] - 0s 242us/step - loss: 0.0169 - val_loss: 0.0187\n",
            "Epoch 22/100\n",
            "323/323 [==============================] - 0s 218us/step - loss: 0.0163 - val_loss: 0.0182\n",
            "Epoch 23/100\n",
            "323/323 [==============================] - 0s 181us/step - loss: 0.0158 - val_loss: 0.0177\n",
            "Epoch 24/100\n",
            "323/323 [==============================] - 0s 204us/step - loss: 0.0154 - val_loss: 0.0173\n",
            "Epoch 25/100\n",
            "323/323 [==============================] - 0s 213us/step - loss: 0.0149 - val_loss: 0.0169\n",
            "Epoch 26/100\n",
            "323/323 [==============================] - 0s 190us/step - loss: 0.0146 - val_loss: 0.0163\n",
            "Epoch 27/100\n",
            "323/323 [==============================] - 0s 197us/step - loss: 0.0142 - val_loss: 0.0160\n",
            "Epoch 28/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0138 - val_loss: 0.0155\n",
            "Epoch 29/100\n",
            "323/323 [==============================] - 0s 228us/step - loss: 0.0134 - val_loss: 0.0152\n",
            "Epoch 30/100\n",
            "323/323 [==============================] - 0s 247us/step - loss: 0.0132 - val_loss: 0.0151\n",
            "Epoch 31/100\n",
            "323/323 [==============================] - 0s 200us/step - loss: 0.0129 - val_loss: 0.0146\n",
            "Epoch 32/100\n",
            "323/323 [==============================] - 0s 199us/step - loss: 0.0126 - val_loss: 0.0146\n",
            "Epoch 33/100\n",
            "323/323 [==============================] - 0s 205us/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 34/100\n",
            "323/323 [==============================] - 0s 188us/step - loss: 0.0122 - val_loss: 0.0141\n",
            "Epoch 35/100\n",
            "323/323 [==============================] - 0s 173us/step - loss: 0.0120 - val_loss: 0.0139\n",
            "Epoch 36/100\n",
            "323/323 [==============================] - 0s 227us/step - loss: 0.0118 - val_loss: 0.0137\n",
            "Epoch 37/100\n",
            "323/323 [==============================] - 0s 206us/step - loss: 0.0116 - val_loss: 0.0136\n",
            "Epoch 38/100\n",
            "323/323 [==============================] - 0s 240us/step - loss: 0.0116 - val_loss: 0.0134\n",
            "Epoch 39/100\n",
            "323/323 [==============================] - 0s 181us/step - loss: 0.0114 - val_loss: 0.0134\n",
            "Epoch 40/100\n",
            "323/323 [==============================] - 0s 202us/step - loss: 0.0113 - val_loss: 0.0133\n",
            "Epoch 41/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0111 - val_loss: 0.0131\n",
            "Epoch 42/100\n",
            "323/323 [==============================] - 0s 198us/step - loss: 0.0109 - val_loss: 0.0130\n",
            "Epoch 43/100\n",
            "323/323 [==============================] - 0s 187us/step - loss: 0.0108 - val_loss: 0.0130\n",
            "Epoch 44/100\n",
            "323/323 [==============================] - 0s 192us/step - loss: 0.0107 - val_loss: 0.0127\n",
            "Epoch 45/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0105 - val_loss: 0.0127\n",
            "Epoch 46/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0106 - val_loss: 0.0128\n",
            "Epoch 47/100\n",
            "323/323 [==============================] - 0s 184us/step - loss: 0.0103 - val_loss: 0.0125\n",
            "Epoch 48/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.0103 - val_loss: 0.0125\n",
            "Epoch 49/100\n",
            "323/323 [==============================] - 0s 197us/step - loss: 0.0101 - val_loss: 0.0126\n",
            "Epoch 50/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0101 - val_loss: 0.0125\n",
            "Epoch 51/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0100 - val_loss: 0.0124\n",
            "Epoch 52/100\n",
            "323/323 [==============================] - 0s 251us/step - loss: 0.0099 - val_loss: 0.0123\n",
            "Epoch 53/100\n",
            "323/323 [==============================] - 0s 184us/step - loss: 0.0098 - val_loss: 0.0124\n",
            "Epoch 54/100\n",
            "323/323 [==============================] - 0s 192us/step - loss: 0.0097 - val_loss: 0.0124\n",
            "Epoch 55/100\n",
            "323/323 [==============================] - 0s 201us/step - loss: 0.0096 - val_loss: 0.0122\n",
            "Epoch 56/100\n",
            "323/323 [==============================] - 0s 215us/step - loss: 0.0095 - val_loss: 0.0120\n",
            "Epoch 57/100\n",
            "323/323 [==============================] - 0s 218us/step - loss: 0.0094 - val_loss: 0.0121\n",
            "Epoch 58/100\n",
            "323/323 [==============================] - 0s 195us/step - loss: 0.0093 - val_loss: 0.0121\n",
            "Epoch 59/100\n",
            "323/323 [==============================] - 0s 185us/step - loss: 0.0092 - val_loss: 0.0119\n",
            "Epoch 60/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0091 - val_loss: 0.0119\n",
            "Epoch 61/100\n",
            "323/323 [==============================] - 0s 213us/step - loss: 0.0090 - val_loss: 0.0120\n",
            "Epoch 62/100\n",
            "323/323 [==============================] - 0s 213us/step - loss: 0.0090 - val_loss: 0.0120\n",
            "Epoch 63/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0088 - val_loss: 0.0117\n",
            "Epoch 64/100\n",
            "323/323 [==============================] - 0s 213us/step - loss: 0.0087 - val_loss: 0.0117\n",
            "Epoch 65/100\n",
            "323/323 [==============================] - 0s 215us/step - loss: 0.0086 - val_loss: 0.0117\n",
            "Epoch 66/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0086 - val_loss: 0.0117\n",
            "Epoch 67/100\n",
            "323/323 [==============================] - 0s 218us/step - loss: 0.0085 - val_loss: 0.0116\n",
            "Epoch 68/100\n",
            "323/323 [==============================] - 0s 185us/step - loss: 0.0085 - val_loss: 0.0116\n",
            "Epoch 69/100\n",
            "323/323 [==============================] - 0s 196us/step - loss: 0.0084 - val_loss: 0.0117\n",
            "Epoch 70/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0083 - val_loss: 0.0116\n",
            "Epoch 71/100\n",
            "323/323 [==============================] - 0s 223us/step - loss: 0.0083 - val_loss: 0.0115\n",
            "Epoch 72/100\n",
            "323/323 [==============================] - 0s 198us/step - loss: 0.0083 - val_loss: 0.0115\n",
            "Epoch 73/100\n",
            "323/323 [==============================] - 0s 203us/step - loss: 0.0082 - val_loss: 0.0115\n",
            "Epoch 74/100\n",
            "323/323 [==============================] - 0s 197us/step - loss: 0.0083 - val_loss: 0.0115\n",
            "Epoch 75/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0081 - val_loss: 0.0116\n",
            "Epoch 76/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0081 - val_loss: 0.0116\n",
            "Epoch 77/100\n",
            "323/323 [==============================] - 0s 201us/step - loss: 0.0080 - val_loss: 0.0115\n",
            "Epoch 78/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0080 - val_loss: 0.0116\n",
            "Epoch 79/100\n",
            "323/323 [==============================] - 0s 205us/step - loss: 0.0080 - val_loss: 0.0114\n",
            "Epoch 80/100\n",
            "323/323 [==============================] - 0s 195us/step - loss: 0.0079 - val_loss: 0.0116\n",
            "Epoch 81/100\n",
            "323/323 [==============================] - 0s 217us/step - loss: 0.0079 - val_loss: 0.0113\n",
            "Epoch 82/100\n",
            "323/323 [==============================] - 0s 239us/step - loss: 0.0080 - val_loss: 0.0116\n",
            "Epoch 83/100\n",
            "323/323 [==============================] - 0s 191us/step - loss: 0.0079 - val_loss: 0.0113\n",
            "Epoch 84/100\n",
            "323/323 [==============================] - 0s 192us/step - loss: 0.0078 - val_loss: 0.0113\n",
            "Epoch 85/100\n",
            "323/323 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0112\n",
            "Epoch 86/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0078 - val_loss: 0.0113\n",
            "Epoch 87/100\n",
            "323/323 [==============================] - 0s 219us/step - loss: 0.0077 - val_loss: 0.0114\n",
            "Epoch 88/100\n",
            "323/323 [==============================] - 0s 226us/step - loss: 0.0077 - val_loss: 0.0112\n",
            "Epoch 89/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0077 - val_loss: 0.0111\n",
            "Epoch 90/100\n",
            "323/323 [==============================] - 0s 212us/step - loss: 0.0076 - val_loss: 0.0113\n",
            "Epoch 91/100\n",
            "323/323 [==============================] - 0s 185us/step - loss: 0.0076 - val_loss: 0.0111\n",
            "Epoch 92/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0076 - val_loss: 0.0110\n",
            "Epoch 93/100\n",
            "323/323 [==============================] - 0s 196us/step - loss: 0.0076 - val_loss: 0.0112\n",
            "Epoch 94/100\n",
            "323/323 [==============================] - 0s 186us/step - loss: 0.0077 - val_loss: 0.0109\n",
            "Epoch 95/100\n",
            "323/323 [==============================] - 0s 207us/step - loss: 0.0077 - val_loss: 0.0112\n",
            "Epoch 96/100\n",
            "323/323 [==============================] - 0s 222us/step - loss: 0.0075 - val_loss: 0.0109\n",
            "Epoch 97/100\n",
            "323/323 [==============================] - 0s 218us/step - loss: 0.0075 - val_loss: 0.0112\n",
            "Epoch 98/100\n",
            "323/323 [==============================] - 0s 199us/step - loss: 0.0074 - val_loss: 0.0110\n",
            "Epoch 99/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.0074 - val_loss: 0.0111\n",
            "Epoch 100/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0074 - val_loss: 0.0109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Jvr-Tu6y5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "pca = PCA(n_components=11)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca  = pca.transform(x_test)\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "np.sum(explained_var[0:11])\n",
        "pca_out = explained_var[0:11]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBoMO64OJnOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model_pca = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(11,)),\n",
        "    Dense(1, kernel_initializer='normal')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2anoSUchJpri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_pca.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSHqeq6_Jsnp",
        "colab_type": "code",
        "outputId": "da44490b-effb-4c64-e75e-14117d317c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trained_model_pca = model_pca.fit(x_train_pca, y_train, batch_size=16, epochs=100, validation_split=0.2)#, validation_data=(x_val, y_val))\n",
        "history_pca = trained_model_pca.history"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 323 samples, validate on 81 samples\n",
            "Epoch 1/100\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.1957 - val_loss: 0.1730\n",
            "Epoch 2/100\n",
            "323/323 [==============================] - 0s 227us/step - loss: 0.1628 - val_loss: 0.1453\n",
            "Epoch 3/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.1347 - val_loss: 0.1211\n",
            "Epoch 4/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.1098 - val_loss: 0.0990\n",
            "Epoch 5/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0869 - val_loss: 0.0795\n",
            "Epoch 6/100\n",
            "323/323 [==============================] - 0s 211us/step - loss: 0.0672 - val_loss: 0.0620\n",
            "Epoch 7/100\n",
            "323/323 [==============================] - 0s 198us/step - loss: 0.0516 - val_loss: 0.0486\n",
            "Epoch 8/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0397 - val_loss: 0.0395\n",
            "Epoch 9/100\n",
            "323/323 [==============================] - 0s 212us/step - loss: 0.0320 - val_loss: 0.0332\n",
            "Epoch 10/100\n",
            "323/323 [==============================] - 0s 196us/step - loss: 0.0271 - val_loss: 0.0288\n",
            "Epoch 11/100\n",
            "323/323 [==============================] - 0s 207us/step - loss: 0.0237 - val_loss: 0.0258\n",
            "Epoch 12/100\n",
            "323/323 [==============================] - 0s 225us/step - loss: 0.0213 - val_loss: 0.0233\n",
            "Epoch 13/100\n",
            "323/323 [==============================] - 0s 216us/step - loss: 0.0192 - val_loss: 0.0218\n",
            "Epoch 14/100\n",
            "323/323 [==============================] - 0s 196us/step - loss: 0.0177 - val_loss: 0.0205\n",
            "Epoch 15/100\n",
            "323/323 [==============================] - 0s 195us/step - loss: 0.0166 - val_loss: 0.0193\n",
            "Epoch 16/100\n",
            "323/323 [==============================] - 0s 216us/step - loss: 0.0154 - val_loss: 0.0184\n",
            "Epoch 17/100\n",
            "323/323 [==============================] - 0s 201us/step - loss: 0.0144 - val_loss: 0.0175\n",
            "Epoch 18/100\n",
            "323/323 [==============================] - 0s 191us/step - loss: 0.0135 - val_loss: 0.0166\n",
            "Epoch 19/100\n",
            "323/323 [==============================] - 0s 187us/step - loss: 0.0128 - val_loss: 0.0160\n",
            "Epoch 20/100\n",
            "323/323 [==============================] - 0s 181us/step - loss: 0.0121 - val_loss: 0.0155\n",
            "Epoch 21/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 22/100\n",
            "323/323 [==============================] - 0s 211us/step - loss: 0.0111 - val_loss: 0.0145\n",
            "Epoch 23/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0107 - val_loss: 0.0143\n",
            "Epoch 24/100\n",
            "323/323 [==============================] - 0s 192us/step - loss: 0.0104 - val_loss: 0.0140\n",
            "Epoch 25/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0101 - val_loss: 0.0137\n",
            "Epoch 26/100\n",
            "323/323 [==============================] - 0s 210us/step - loss: 0.0099 - val_loss: 0.0135\n",
            "Epoch 27/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0097 - val_loss: 0.0133\n",
            "Epoch 28/100\n",
            "323/323 [==============================] - 0s 273us/step - loss: 0.0095 - val_loss: 0.0132\n",
            "Epoch 29/100\n",
            "323/323 [==============================] - 0s 219us/step - loss: 0.0093 - val_loss: 0.0132\n",
            "Epoch 30/100\n",
            "323/323 [==============================] - 0s 232us/step - loss: 0.0093 - val_loss: 0.0130\n",
            "Epoch 31/100\n",
            "323/323 [==============================] - 0s 227us/step - loss: 0.0091 - val_loss: 0.0127\n",
            "Epoch 32/100\n",
            "323/323 [==============================] - 0s 219us/step - loss: 0.0090 - val_loss: 0.0126\n",
            "Epoch 33/100\n",
            "323/323 [==============================] - 0s 205us/step - loss: 0.0089 - val_loss: 0.0125\n",
            "Epoch 34/100\n",
            "323/323 [==============================] - 0s 235us/step - loss: 0.0089 - val_loss: 0.0122\n",
            "Epoch 35/100\n",
            "323/323 [==============================] - 0s 221us/step - loss: 0.0088 - val_loss: 0.0124\n",
            "Epoch 36/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0088 - val_loss: 0.0122\n",
            "Epoch 37/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0086 - val_loss: 0.0120\n",
            "Epoch 38/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.0119\n",
            "Epoch 39/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0085 - val_loss: 0.0119\n",
            "Epoch 40/100\n",
            "323/323 [==============================] - 0s 191us/step - loss: 0.0085 - val_loss: 0.0117\n",
            "Epoch 41/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0083 - val_loss: 0.0119\n",
            "Epoch 42/100\n",
            "323/323 [==============================] - 0s 230us/step - loss: 0.0083 - val_loss: 0.0117\n",
            "Epoch 43/100\n",
            "323/323 [==============================] - 0s 199us/step - loss: 0.0082 - val_loss: 0.0116\n",
            "Epoch 44/100\n",
            "323/323 [==============================] - 0s 207us/step - loss: 0.0082 - val_loss: 0.0117\n",
            "Epoch 45/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0082 - val_loss: 0.0116\n",
            "Epoch 46/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.0081 - val_loss: 0.0113\n",
            "Epoch 47/100\n",
            "323/323 [==============================] - 0s 211us/step - loss: 0.0080 - val_loss: 0.0114\n",
            "Epoch 48/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0080 - val_loss: 0.0114\n",
            "Epoch 49/100\n",
            "323/323 [==============================] - 0s 204us/step - loss: 0.0079 - val_loss: 0.0112\n",
            "Epoch 50/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.0112\n",
            "Epoch 51/100\n",
            "323/323 [==============================] - 0s 226us/step - loss: 0.0078 - val_loss: 0.0112\n",
            "Epoch 52/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0079 - val_loss: 0.0109\n",
            "Epoch 53/100\n",
            "323/323 [==============================] - 0s 215us/step - loss: 0.0077 - val_loss: 0.0111\n",
            "Epoch 54/100\n",
            "323/323 [==============================] - 0s 225us/step - loss: 0.0078 - val_loss: 0.0111\n",
            "Epoch 55/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0077 - val_loss: 0.0111\n",
            "Epoch 56/100\n",
            "323/323 [==============================] - 0s 193us/step - loss: 0.0076 - val_loss: 0.0110\n",
            "Epoch 57/100\n",
            "323/323 [==============================] - 0s 242us/step - loss: 0.0076 - val_loss: 0.0110\n",
            "Epoch 58/100\n",
            "323/323 [==============================] - 0s 195us/step - loss: 0.0076 - val_loss: 0.0110\n",
            "Epoch 59/100\n",
            "323/323 [==============================] - 0s 189us/step - loss: 0.0075 - val_loss: 0.0108\n",
            "Epoch 60/100\n",
            "323/323 [==============================] - 0s 204us/step - loss: 0.0074 - val_loss: 0.0108\n",
            "Epoch 61/100\n",
            "323/323 [==============================] - 0s 200us/step - loss: 0.0074 - val_loss: 0.0107\n",
            "Epoch 62/100\n",
            "323/323 [==============================] - 0s 231us/step - loss: 0.0073 - val_loss: 0.0107\n",
            "Epoch 63/100\n",
            "323/323 [==============================] - 0s 222us/step - loss: 0.0073 - val_loss: 0.0108\n",
            "Epoch 64/100\n",
            "323/323 [==============================] - 0s 223us/step - loss: 0.0073 - val_loss: 0.0106\n",
            "Epoch 65/100\n",
            "323/323 [==============================] - 0s 183us/step - loss: 0.0073 - val_loss: 0.0106\n",
            "Epoch 66/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.0107\n",
            "Epoch 67/100\n",
            "323/323 [==============================] - 0s 199us/step - loss: 0.0072 - val_loss: 0.0106\n",
            "Epoch 68/100\n",
            "323/323 [==============================] - 0s 229us/step - loss: 0.0071 - val_loss: 0.0106\n",
            "Epoch 69/100\n",
            "323/323 [==============================] - 0s 223us/step - loss: 0.0071 - val_loss: 0.0105\n",
            "Epoch 70/100\n",
            "323/323 [==============================] - 0s 228us/step - loss: 0.0071 - val_loss: 0.0102\n",
            "Epoch 71/100\n",
            "323/323 [==============================] - 0s 235us/step - loss: 0.0072 - val_loss: 0.0099\n",
            "Epoch 72/100\n",
            "323/323 [==============================] - 0s 221us/step - loss: 0.0071 - val_loss: 0.0101\n",
            "Epoch 73/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0071 - val_loss: 0.0100\n",
            "Epoch 74/100\n",
            "323/323 [==============================] - 0s 213us/step - loss: 0.0070 - val_loss: 0.0102\n",
            "Epoch 75/100\n",
            "323/323 [==============================] - 0s 220us/step - loss: 0.0069 - val_loss: 0.0102\n",
            "Epoch 76/100\n",
            "323/323 [==============================] - 0s 269us/step - loss: 0.0069 - val_loss: 0.0102\n",
            "Epoch 77/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0068 - val_loss: 0.0102\n",
            "Epoch 78/100\n",
            "323/323 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.0099\n",
            "Epoch 79/100\n",
            "323/323 [==============================] - 0s 206us/step - loss: 0.0068 - val_loss: 0.0103\n",
            "Epoch 80/100\n",
            "323/323 [==============================] - 0s 197us/step - loss: 0.0068 - val_loss: 0.0101\n",
            "Epoch 81/100\n",
            "323/323 [==============================] - 0s 205us/step - loss: 0.0068 - val_loss: 0.0100\n",
            "Epoch 82/100\n",
            "323/323 [==============================] - 0s 200us/step - loss: 0.0067 - val_loss: 0.0100\n",
            "Epoch 83/100\n",
            "323/323 [==============================] - 0s 218us/step - loss: 0.0067 - val_loss: 0.0100\n",
            "Epoch 84/100\n",
            "323/323 [==============================] - 0s 206us/step - loss: 0.0067 - val_loss: 0.0101\n",
            "Epoch 85/100\n",
            "323/323 [==============================] - 0s 201us/step - loss: 0.0066 - val_loss: 0.0099\n",
            "Epoch 86/100\n",
            "323/323 [==============================] - 0s 227us/step - loss: 0.0066 - val_loss: 0.0098\n",
            "Epoch 87/100\n",
            "323/323 [==============================] - 0s 216us/step - loss: 0.0066 - val_loss: 0.0099\n",
            "Epoch 88/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0065 - val_loss: 0.0098\n",
            "Epoch 89/100\n",
            "323/323 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0100\n",
            "Epoch 90/100\n",
            "323/323 [==============================] - 0s 217us/step - loss: 0.0065 - val_loss: 0.0099\n",
            "Epoch 91/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0065 - val_loss: 0.0098\n",
            "Epoch 92/100\n",
            "323/323 [==============================] - 0s 224us/step - loss: 0.0065 - val_loss: 0.0099\n",
            "Epoch 93/100\n",
            "323/323 [==============================] - 0s 233us/step - loss: 0.0064 - val_loss: 0.0097\n",
            "Epoch 94/100\n",
            "323/323 [==============================] - 0s 215us/step - loss: 0.0064 - val_loss: 0.0098\n",
            "Epoch 95/100\n",
            "323/323 [==============================] - 0s 209us/step - loss: 0.0063 - val_loss: 0.0097\n",
            "Epoch 96/100\n",
            "323/323 [==============================] - 0s 190us/step - loss: 0.0063 - val_loss: 0.0098\n",
            "Epoch 97/100\n",
            "323/323 [==============================] - 0s 194us/step - loss: 0.0063 - val_loss: 0.0099\n",
            "Epoch 98/100\n",
            "323/323 [==============================] - 0s 214us/step - loss: 0.0063 - val_loss: 0.0096\n",
            "Epoch 99/100\n",
            "323/323 [==============================] - 0s 206us/step - loss: 0.0063 - val_loss: 0.0097\n",
            "Epoch 100/100\n",
            "323/323 [==============================] - 0s 221us/step - loss: 0.0062 - val_loss: 0.0097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAkKjEpBKkT7",
        "colab_type": "code",
        "outputId": "e8bc5ce7-bc35-4386-aea5-bf775879b691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "max_loss = max(history['val_loss'])\n",
        "min_loss = min(history['val_loss'])\n",
        "\n",
        "max_loss_pca = max(history_pca['val_loss'])\n",
        "min_loss_pca = min(history_pca['val_loss'])\n",
        "\n",
        "print('Max_loss and Min_loss are', max_loss,',', min_loss,'.')\n",
        "print('Max_loss_pca and Min_loss_pca are', max_loss_pca,',', min_loss_pca,'.')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max_loss and Min_loss are 0.09721499629732636 , 0.010896338018937968 .\n",
            "Max_loss_pca and Min_loss_pca are 0.17301385113854467 , 0.00963814733527945 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmBnX6h_Migd",
        "colab_type": "code",
        "outputId": "3932bb4f-b721-4564-9961-1c3eba42d85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Loss_ = history['val_loss']\n",
        "Loss_pca = history_pca['val_loss']\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('val_Loss')\n",
        "plt.plot(Loss_, 'darkred')\n",
        "plt.plot(Loss_pca,'darkgreen')\n",
        "plt.legend(['val_loss without pca','val_loss with pca'])\n",
        "plt.show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEJCAYAAABhbdtlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ0sSxhhj+mRJwhhjTJ8sSRhjjOnT/weqcsLZtEsEsgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}